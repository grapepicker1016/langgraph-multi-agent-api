{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=3)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONDecodeError\n",
    "from typing import List, Union\n",
    "\n",
    "from langchain_core.agents import AgentAction, AgentActionMessageLog, AgentFinish\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    ")\n",
    "from langchain_core.outputs import ChatGeneration, Generation\n",
    "\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "\n",
    "\n",
    "class OpenAIFunctionsAgentOutputParser(AgentOutputParser):\n",
    "    \"\"\"Parses a message into agent action/finish.\n",
    "\n",
    "    Is meant to be used with OpenAI models, as it relies on the specific\n",
    "    function_call parameter from OpenAI to convey what tools to use.\n",
    "\n",
    "    If a function_call parameter is passed, then that is used to get\n",
    "    the tool and tool input.\n",
    "\n",
    "    If one is not passed, then the AIMessage is assumed to be the final output.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"openai-functions-agent\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_ai_message(message: BaseMessage) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"Parse an AI message.\"\"\"\n",
    "        if not isinstance(message, AIMessage):\n",
    "            raise TypeError(f\"Expected an AI message got {type(message)}\")\n",
    "\n",
    "        function_call = message.additional_kwargs.get(\"function_call\", {})\n",
    "\n",
    "        if function_call:\n",
    "            function_name = function_call[\"name\"]\n",
    "            try:\n",
    "                if len(function_call[\"arguments\"].strip()) == 0:\n",
    "                    # OpenAI returns an empty string for functions containing no args\n",
    "                    _tool_input = {}\n",
    "                else:\n",
    "                    # otherwise it returns a json object\n",
    "                    _tool_input = json.loads(function_call[\"arguments\"], strict=False)\n",
    "            except JSONDecodeError:\n",
    "                raise OutputParserException(\n",
    "                    f\"Could not parse tool input: {function_call} because \"\n",
    "                    f\"the `arguments` is not valid JSON.\"\n",
    "                )\n",
    "\n",
    "            # HACK HACK HACK:\n",
    "            # The code that encodes tool input into Open AI uses a special variable\n",
    "            # name called `__arg1` to handle old style tools that do not expose a\n",
    "            # schema and expect a single string argument as an input.\n",
    "            # We unpack the argument here if it exists.\n",
    "            # Open AI does not support passing in a JSON array as an argument.\n",
    "            if \"__arg1\" in _tool_input:\n",
    "                tool_input = _tool_input[\"__arg1\"]\n",
    "            else:\n",
    "                tool_input = _tool_input\n",
    "\n",
    "            content_msg = f\"responded: {message.content}\\n\" if message.content else \"\\n\"\n",
    "            log = f\"\\nInvoking: `{function_name}` with `{tool_input}`\\n{content_msg}\\n\"\n",
    "            return AgentActionMessageLog(\n",
    "                tool=function_name,\n",
    "                tool_input=tool_input,\n",
    "                log=log,\n",
    "                message_log=[message],\n",
    "            )\n",
    "\n",
    "        return AgentFinish(\n",
    "            return_values={\"output\": message.content}, log=str(message.content)\n",
    "        )\n",
    "\n",
    "    def parse_result(\n",
    "        self, result: List[Generation], *, partial: bool = False\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        if not isinstance(result[0], ChatGeneration):\n",
    "            raise ValueError(\"This output parser only works on ChatGeneration output\")\n",
    "        message = result[0].message\n",
    "        return self._parse_ai_message(message)\n",
    "\n",
    "    def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
    "        raise ValueError(\"Can only parse messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough\n",
    "from langchain.agents.format_scratchpad.openai_functions import (\n",
    "    format_to_openai_function_messages,\n",
    ")\n",
    "\n",
    "# from langchain.agents.output_parsers.openai_functions import (\n",
    "#     OpenAIFunctionsAgentOutputParser,\n",
    "# )\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# Choose the LLM that will drive the agent\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")\n",
    "\n",
    "# llm = OllamaFunctions(model='mistral:7b-instruct-v0.2-q6_K', tool_system_prompt_template='')\n",
    "\n",
    "llm = OllamaFunctions(model='mistral:7b-instruct-v0.2-q8_0', )\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "# llm_with_tools = llm.bind(functions=[convert_to_openai_function(t) for t in tools])\n",
    "\n",
    "llm_with_tools = llm.bind(\n",
    "    functions=[\n",
    "    {'name': 'tavily_search_results_json', \n",
    "     'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer     questions about current events. Input should be a search query.', \n",
    "     'parameters': {'type': 'object', \n",
    "                    'properties': \n",
    "                        {'query': {'description': 'search query to look up', 'type': 'string'}}, \n",
    "                        'required': ['query']}}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        )\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=OllamaFunctions(llm=ChatOllama(model='mistral:7b-instruct-v0.2-q8_0', format='json'), tool_system_prompt_template='You have access to the following tools:\\n\\n{tools}\\n\\nYou must always select one of the above tools and respond with only a JSON object matching the following schema:\\n\\n{{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}}\\n'), kwargs={'functions': [{'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer     questions about current events. Input should be a search query.', 'parameters': {'type': 'object', 'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query']}}]})\n",
       "| OpenAIFunctionsAgentOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_agent_executor\n",
    "\n",
    "agent_executor = create_agent_executor(agent, tools)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[pregel/step]\u001b[0m \u001b[1mStarting step 0 with 1 task. Next tasks:\n",
      "\u001b[0m- __start__({'chat_history': [], 'input': 'who is the winnner of the us open'})\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 2:chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 2:chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"who is the winnner of the us open\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 3:chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 3:chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 4:chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 4:chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"not_implemented\",\n",
      "  \"id\": [\n",
      "    \"builtins\",\n",
      "    \"object\"\n",
      "  ],\n",
      "  \"repr\": \"<object object at 0x7fda9c1ee0e0>\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 5:chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 5:chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"not_implemented\",\n",
      "  \"id\": [\n",
      "    \"builtins\",\n",
      "    \"object\"\n",
      "  ],\n",
      "  \"repr\": \"<object object at 0x7fda9c1ee0e0>\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 6:chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 6:chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[pregel/checkpoint]\u001b[0m \u001b[1mFinishing step 0. Channel values:\n",
      "\u001b[0m{'__start__': {...},\n",
      " '__start__:inbox': {...},\n",
      " 'chat_history': [],\n",
      " 'input': 'who is the winnner of the us open',\n",
      " 'intermediate_steps': [],\n",
      " <ReservedChannels.is_last_step: 'is_last_step'>: False}\n",
      "\u001b[36;1m\u001b[1;3m[pregel/step]\u001b[0m \u001b[1mStarting step 1 with 1 task. Next tasks:\n",
      "\u001b[0m- __start__:edges({'chat_history': [], 'input': 'who is the winnner of the us open'})\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges > 8:chain:ChannelRead<['input', 'chat_history', 'agent_outcome', 'intermediate_steps']>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges > 8:chain:ChannelRead<['input', 'chat_history', 'agent_outcome', 'intermediate_steps']>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges > 9:chain:ChannelWrite<agent:inbox>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges > 9:chain:ChannelWrite<agent:inbox>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 7:chain:__start__:edges] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[pregel/checkpoint]\u001b[0m \u001b[1mFinishing step 1. Channel values:\n",
      "\u001b[0m{'__start__:inbox': {...},\n",
      " 'agent:inbox': {...},\n",
      " 'chat_history': [],\n",
      " 'input': 'who is the winnner of the us open',\n",
      " 'intermediate_steps': [],\n",
      " <ReservedChannels.is_last_step: 'is_last_step'>: False}\n",
      "\u001b[36;1m\u001b[1;3m[pregel/step]\u001b[0m \u001b[1mStarting step 2 with 1 task. Next tasks:\n",
      "\u001b[0m- agent({'agent_outcome': None,\n",
      " 'chat_history': [],\n",
      " 'input': 'who is the winnner of the us open',\n",
      " 'intermediate_steps': []})\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 11:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 11:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad> > 16:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad> > 16:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad> > 15:chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 14:chain:RunnableAssign<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 17:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"who is the winnner of the us open\",\n",
      "  \"chat_history\": [],\n",
      "  \"agent_outcome\": null,\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 17:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"SystemMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are a helpful assistant\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"who is the winnner of the us open\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 18:llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: who is the winnner of the us open\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:LangGraph > 10:chain:agent > 12:chain:run_agent > 13:chain:RunnableSequence > 19:llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You have access to the following tools:\\n\\n[\\n  {\\n    \\\"name\\\": \\\"tavily_search_results_json\\\",\\n    \\\"description\\\": \\\"A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer     questions about current events. Input should be a search query.\\\",\\n    \\\"parameters\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"query\\\": {\\n          \\\"description\\\": \\\"search query to look up\\\",\\n          \\\"type\\\": \\\"string\\\"\\n        }\\n      },\\n      \\\"required\\\": [\\n        \\\"query\\\"\\n      ]\\n    }\\n  }\\n]\\n\\nYou must always select one of the above tools and respond with only a JSON object matching the following schema:\\n\\n{\\n  \\\"tool\\\": <name of the selected tool>,\\n  \\\"tool_input\\\": <parameters for the selected tool, matching the tool's JSON schema>\\n}\\n\\nSystem: You are a helpful assistant\\nHuman: who is the winnner of the us open\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:LangGraph] [4487.65s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()Traceback (most recent call last):\\n\\n\\n  File \\\"/home/amaithi/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py\\\", line 471, in get_executor_for_config\\n    yield executor\\n\\n\\n  File \\\"/home/amaithi/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py\\\", line 348, in _transform\\n    done, inflight = concurrent.futures.wait(\\n                     ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/lib/python3.11/concurrent/futures/_base.py\\\", line 305, in wait\\n    waiter.event.wait(timeout)\\n\\n\\n  File \\\"/usr/lib/python3.11/threading.py\\\", line 622, in wait\\n    signaled = self._cond.wait(timeout)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/usr/lib/python3.11/threading.py\\\", line 320, in wait\\n    waiter.acquire()\\n\\n\\nKeyboardInterrupt\\n\\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"/home/amaithi/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py\\\", line 1513, in _transform_stream_with_config\\n    chunk: Output = context.run(next, iterator)  # type: ignore\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"/home/amaithi/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py\\\", line 278, in _transform\\n    with ChannelsManager(\\n\\n\\n  File \\\"/usr/lib/python3.11/contextlib.py\\\", line 155, in __exit__\\n    self.gen.throw(typ, value, traceback)\\n\\n\\n  File \\\"/home/amaithi/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py\\\", line 468, in get_executor_for_config\\n    with ContextThreadPoolExecutor(\\n\\n\\n  File \\\"/usr/lib/python3.11/concurrent/futures/_base.py\\\", line 647, in __exit__\\n    self.shutdown(wait=True)\\n\\n\\n  File \\\"/usr/lib/python3.11/concurrent/futures/thread.py\\\", line 235, in shutdown\\n    t.join()\\n\\n\\n  File \\\"/usr/lib/python3.11/threading.py\\\", line 1112, in join\\n    self._wait_for_tstate_lock()\\n\\n\\n  File \\\"/usr/lib/python3.11/threading.py\\\", line 1132, in _wait_for_tstate_lock\\n    if lock.acquire(block, timeout):\\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\nKeyboardInterrupt\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:471\u001b[0m, in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextThreadPoolExecutor(\n\u001b[1;32m    469\u001b[0m     max_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m executor\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:348\u001b[0m, in \u001b[0;36mPregel._transform\u001b[0;34m(self, input, run_manager, config, input_keys, output_keys, interrupt)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# execute tasks, and wait for one to fail or all to finish.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# each task is independent from all other concurrent tasks\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# interrupt on failure or timeout\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwho is the winnner of the us open\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:579\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[1;32m    578\u001b[0m     latest: Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m latest\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:615\u001b[0m, in \u001b[0;36mPregel.transform\u001b[0;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]]:\n\u001b[0;32m--> 615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_stream_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1513\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1513\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:278\u001b[0m, in \u001b[0;36mPregel._transform\u001b[0;34m(self, input, run_manager, config, input_keys, output_keys, interrupt)\u001b[0m\n\u001b[1;32m    276\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m checkpoint \u001b[38;5;129;01mor\u001b[39;00m empty_checkpoint()\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# create channels from checkpoint\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mChannelsManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_executor_for_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# map inputs to channel updates\u001b[39;49;00m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_writes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# discard any unfinished tasks from previous checkpoint\u001b[39;49;00m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_prepare_next_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/projects/weaviate/langgraph-scratch/.venv/lib/python3.11/site-packages/langchain_core/runnables/config.py:468\u001b[0m, in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get an executor for a config.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Generator[Executor, None, None]: The executor.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 468\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mContextThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_concurrency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"who is the winnner of the us open\", \"chat_history\": []}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
